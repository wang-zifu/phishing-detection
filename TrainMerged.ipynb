{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/merged/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6486097, 315525, 2287232, 95308, 11921)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(data_path / 'benign.csv')\n",
    "df_malware = pd.read_csv(data_path / 'malware.csv')\n",
    "df_phishing = pd.read_csv(data_path / 'phishing.csv')\n",
    "df_attacked = pd.read_csv(data_path / 'attacked.csv')\n",
    "df_spam = pd.read_csv(data_path / 'spam.csv')\n",
    "\n",
    "len(df_benign), len(df_malware), len(df_phishing), len(df_attacked), len(df_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or Structured Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When needed\n",
    "columns = ['url_len', 'url_n_alpha', 'url_n_ampersand', 'url_n_digit', 'url_n_dot', 'url_n_equal', 'url_n_question_mark', 'url_n_semicolon', 'url_n_sp_char', 'url_n_underscore', 'url_rate_digit', 'url_ratio_digit_letter', 'domain_is_ip', 'domain_len', 'domain_n_at_sign', 'domain_n_digit', 'domain_n_hyphen', 'domain_n_nonalnum', 'primary_domain_entropy', 'primary_domain_len', 'primary_domain_n_at_sign', 'primary_domain_n_digit', 'primary_domain_n_hyphen', 'primary_domain_n_nonalnum', 'subdomain_len', 'subdomain_n', 'subdomain_n_dot', 'path_avglen_dir', 'path_dir_rate_digit', 'path_len', 'path_maxlen_dir', 'path_n_digit', 'path_n_dir', 'path_n_double_slash', 'path_n_sp_char', 'path_n_zero', 'path_percent20_in', 'path_rate_digit', 'path_ratio_upper_lower', 'path_single_char_dir_in', 'path_upper_dir_in', 'params_len', 'query_len', 'query_n', 'query_n_digit', 'name_len', 'name_n_digit', 'name_rate_digit', 'ratio_domain_url', 'ratio_path_domain', 'ratio_path_url', 'ratio_query_domain', 'ratio_query_path', 'ratio_query_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6485136, 315480, 2285553, 95308, 11921)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign = pd.read_csv(data_path / 'benign_structured.csv')\n",
    "df_malware = pd.read_csv(data_path / 'malware_structured.csv')\n",
    "df_phishing = pd.read_csv(data_path / 'phishing_structured.csv')\n",
    "df_attacked = pd.read_csv(data_path / 'attacked_structured.csv')\n",
    "df_spam = pd.read_csv(data_path / 'spam_structured.csv')\n",
    "\n",
    "len(df_benign), len(df_malware), len(df_phishing), len(df_attacked), len(df_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only once!!!!\n",
    "bool_cols = ['domain_is_ip', 'path_percent20_in', 'path_single_char_dir_in', 'path_upper_dir_in']\n",
    "for col in bool_cols:\n",
    "    df_benign[col] = df_benign[col] == 'True'\n",
    "    df_benign[col] = df_benign[col].astype(np.int)\n",
    "    df_malware[col] = df_malware[col] == 'True'\n",
    "    df_malware[col] = df_malware[col].astype(np.int)\n",
    "    df_phishing[col] = df_phishing[col] == 'True'\n",
    "    df_phishing[col] = df_phishing[col].astype(np.int)\n",
    "    df_attacked[col] = df_attacked[col] == 'True'\n",
    "    df_attacked[col] = df_attacked[col].astype(np.int)\n",
    "    df_spam[col] = df_spam[col] == 'True'\n",
    "    df_spam[col] = df_spam[col].astype(np.int)\n",
    "\n",
    "df_benign.to_csv(data_path / 'benign_structured.csv', index=False)\n",
    "df_malware.to_csv(data_path / 'malware_structured.csv', index=False)\n",
    "df_phishing.to_csv(data_path / 'phishing_structured.csv', index=False)\n",
    "df_attacked.to_csv(data_path / 'attacked_structured.csv', index=False)\n",
    "df_spam.to_csv(data_path / 'spam_structured.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = df_benign.sample(n=9000, random_state=119)\n",
    "df_malware = df_malware.sample(n=500, random_state=119)\n",
    "df_phishing = df_phishing.sample(n=9000, random_state=119)\n",
    "df_attacked = df_attacked.sample(n=9000, random_state=119)\n",
    "df_spam = df_spam.sample(n=9000, random_state=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign['CLASS_LABEL'] = [0] * len(df_benign)\n",
    "df_malware['CLASS_LABEL'] = [1] * len(df_malware)\n",
    "df_phishing['CLASS_LABEL'] = [2] * len(df_phishing)\n",
    "df_attacked['CLASS_LABEL'] = [3] * len(df_attacked)\n",
    "df_spam['CLASS_LABEL'] = [4] * len(df_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([df_benign, df_malware, df_phishing, df_attacked, df_spam], ignore_index=True)\n",
    "y_train = X_train.pop('CLASS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=119)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.url).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test.url).toarray()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from tpot.config import classifier_config_dict\n",
    "\n",
    "d = dict(classifier_config_dict)\n",
    "d.pop('sklearn.naive_bayes.GaussianNB')\n",
    "d.pop('sklearn.naive_bayes.BernoulliNB')\n",
    "d.pop('sklearn.naive_bayes.MultinomialNB')\n",
    "d.pop('sklearn.tree.DecisionTreeClassifier')\n",
    "d.pop('sklearn.ensemble.ExtraTreesClassifier')\n",
    "d.pop('sklearn.ensemble.GradientBoostingClassifier')\n",
    "d.pop('sklearn.ensemble.RandomForestClassifier')\n",
    "d.pop('sklearn.neighbors.KNeighborsClassifier')\n",
    "d.pop('sklearn.svm.LinearSVC')\n",
    "d.pop('sklearn.linear_model.SGDClassifier')\n",
    "d.pop('sklearn.linear_model.LogisticRegression')\n",
    "d['sklearn.decomposition.PCA']['iterated_power'] = range(1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config_sparse = {\n",
    "    'tpot.builtins.OneHotEncoder': {\n",
    "        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf':  range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'nthread': [1]\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': np.arange(0.05, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.RFE': {\n",
    "        'step': np.arange(0.05, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFromModel': {\n",
    "        'threshold': np.arange(0, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=4, verbosity=2, n_jobs=8, random_state=119, config_dict=classifier_config_sparse)\n",
    "tpot.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(tpot.score(X_test_tfidf, y_test))\n",
    "tpot.export('tpot_pipelines/tpot_tfidf_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
